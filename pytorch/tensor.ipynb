{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![介绍](img.png)\n",
    "张量就是多维数组\n",
    "张量的阶数就是张量的维度\n",
    "张量的阶数也叫做张量的秩"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Variable\n",
    "Variable 是pytorch中的变量 在0.4.0版本中Variable已经被弃用 并入到了tensor中\n",
    "\n",
    "- data：保存Variable所包含的tensor\n",
    "- grad：保存data对应的梯度，grad也是个Variable而不是tensor，它和data的形状一样\n",
    "- grad_fn：指向一个Function对象，这个Function用来反向传播计算输入的梯度\n",
    "  创建这个张量的函数，是自动求导的关键\n",
    "- requires_grad:指示是否需要梯度\n",
    "- is_leaf:指示是否是叶子节点，叶子节点指的是用户创建的变量，非叶子节点指的是通过一些操作得到的变量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tensor\n",
    "Tensor是pytorch中的张量，和numpy中的array很类似\n",
    "Tensor和numpy的array之间最大的区别就是Tensor可以在GPU上加速运算\n",
    "Tensor和numpy的array之间可以无缝的转换，且二者共享内存\n",
    "\n",
    "![](img_1.png)\n",
    "在Variable的基础上，扩展了下列字段\n",
    "\n",
    "- dtype:指定tensor的数据类型\n",
    "  - torch.FloatTensor:32位浮点型\n",
    "  - torch.DoubleTensor:64位浮点型\n",
    "  - torch.cuda.FloatTensor:32位浮点型，存储在GPU上\n",
    "- shape:指定张量的形状\n",
    "  如(64,3,32,32)表示一个64张32x32的彩色图片组成的batch\n",
    "  (64,3,224,224)表示一个64张224x224的彩色图片组成的batch\n",
    "- device:当前数据分配到什么内存上，cpu的内存或gpu显存\n",
    "  - torch.device('cuda')\n",
    "  - torch.device('cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# 创建Tensor\n",
    "# 从data创建tensor\n",
    "# 创建一个numpy数组\n",
    "# arr 是长宽为3的二维数组\n",
    "arr = np.ones((3,3))\n",
    "\n",
    "# 从list创建tensor\n",
    "t1 = torch.tensor(arr, dtype=None, device='cpu', requires_grad=False)\n",
    "# 对于没有cuda的电脑，下面这句话会报错\n",
    "# tensor = torch.tensor(arr, dtype=None, device='cuda', requires_grad=False)\n",
    "\n",
    "print(t1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T05:57:48.262660Z",
     "start_time": "2023-09-20T05:57:48.257744Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "140316727855408\n",
      "140317270392976\n"
     ]
    }
   ],
   "source": [
    "# 从numpy创建tensor 会共享内存\n",
    "t2 = torch.from_numpy(arr)\n",
    "print(t2)\n",
    "print(id(arr))\n",
    "print(id(t2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T06:03:52.436171Z",
     "start_time": "2023-09-20T06:03:52.426669Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "140317270404896\n",
      "140317270404896\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 使用torch.zeros创建tensor\n",
    "# 会根据指定的shape创建一个全是0的tensor\n",
    "\n",
    "# 任意声明一个tensor\n",
    "out_t = torch.tensor([11])\n",
    "print(out_t)\n",
    "# create a tensor with shape(3,3) and full of 0\n",
    "# 并赋值给out_t\n",
    "# 返回的t指向的内存地址和out_t是一样的\n",
    "t = torch.zeros((3,3), out=out_t)\n",
    "print(out_t)\n",
    "print(t)\n",
    "print(id(out_t))\n",
    "print(id(t))\n",
    "print(id(t) == id(out_t))\n",
    "\n",
    "\n",
    "# 类似于numpy的使用 还有torch.ones torch.full torch.arange torch.linspace torch.rand torch.normal\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T06:12:15.313832Z",
     "start_time": "2023-09-20T06:12:15.308931Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 7, 7],\n",
      "        [7, 7, 7],\n",
      "        [7, 7, 7]])\n"
     ]
    }
   ],
   "source": [
    "# 使用数来填充的张量\n",
    "t7 = torch.full((3,3), 7)\n",
    "print(t7)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T06:19:52.903955Z",
     "start_time": "2023-09-20T06:19:52.887134Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "# 使用arange创建张量\n",
    "# 从2到10 前闭后开 步长为2\n",
    "t8 = torch.arange(2,10,2)\n",
    "print(t8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T06:23:19.262840Z",
     "start_time": "2023-09-20T06:23:19.256736Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.,  4.,  6.,  8., 10.])\n"
     ]
    }
   ],
   "source": [
    "# 使用linspace创建张量\n",
    "# 从2到10 前闭后闭 一共有5个数\n",
    "t9 = torch.linspace(2,10,5)\n",
    "print(t9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T06:23:09.950451Z",
     "start_time": "2023-09-20T06:23:09.932063Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 创建对角张量\n",
    "# 对角线上的元素为1\n",
    "# 对角线的偏移量为0\n",
    "t10 = torch.eye(3,3)\n",
    "print(t10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T06:24:16.428432Z",
     "start_time": "2023-09-20T06:24:16.411203Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0160,  0.4011,  1.5175],\n",
      "        [-0.8173, -0.7611, -1.3684],\n",
      "        [ 1.1762,  0.1815, -1.6923]])\n"
     ]
    }
   ],
   "source": [
    "# 创建正态分布张量 高斯分布\n",
    "# mean:张量的均值\n",
    "# std:张量的标准差\n",
    "t11 = torch.normal(mean=torch.zeros(3,3), std=torch.ones(3,3))\n",
    "print(t11)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T06:24:51.312263Z",
     "start_time": "2023-09-20T06:24:51.296005Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0130, -1.0850, -0.6784],\n",
      "        [-0.5729,  0.7610,  0.9752],\n",
      "        [ 0.8611,  0.4730,  0.5292]])\n"
     ]
    }
   ],
   "source": [
    "# 创建随机张量\n",
    "t12 = torch.randn(3,3)\n",
    "print(t12)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T06:38:35.847470Z",
     "start_time": "2023-09-20T06:38:35.828654Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9034, 0.1475, 0.3576],\n",
      "        [0.1560, 0.6016, 0.7550],\n",
      "        [0.3019, 0.0696, 0.0842]])\n"
     ]
    }
   ],
   "source": [
    "# 创建均匀分布张量\n",
    "t13 = torch.rand(3,3)\n",
    "print(t13)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T06:39:49.240409Z",
     "start_time": "2023-09-20T06:39:49.223872Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 4, 5, 7, 2, 3, 9, 1, 8, 6])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 依概率分布创建张量\n",
    "# 生成从0到n-1的随机排列\n",
    "torch.randperm(10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T06:41:30.622367Z",
     "start_time": "2023-09-20T06:41:30.598893Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# bernoulli分布\n",
    "t15 = torch.bernoulli(t13)\n",
    "print(t15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T06:42:50.166673Z",
     "start_time": "2023-09-20T06:42:50.148374Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tensor的操作\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cat():\n",
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 20, 30]])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# cat 拼接\n",
    "# 将多个张量沿着指定的维度拼接在一起，返回一个新的张量。\n",
    "# 拼接操作会将张量的所有元素沿着指定的维度依次排列，可能会改变张量内部的数据分布。\n",
    "# tensors：要拼接的张量的列表\n",
    "# dim：拼接的维度 0表示按行拼接（纵向） 1表示按列拼接（横向）\n",
    "\n",
    "# 创建 [[1, 2, 3], [4, 5, 6]] 的 tensor\n",
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "b = torch.tensor([[7, 8, 9], [10, 20, 30]])\n",
    "# 使用 torch.cat() 将 a 和 b 沿着第一个维度拼接\n",
    "d = torch.cat([a, b], dim=0)\n",
    "print(\"torch.cat():\")\n",
    "print(d)\n",
    "# d的shape\n",
    "print(d.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T07:12:19.804221Z",
     "start_time": "2023-09-20T07:12:19.799137Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.stack():\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 20, 30]]])\n",
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# stack 堆叠\n",
    "# 将多个张量沿着指定的维度堆叠在一起，返回一个新的张量。\n",
    "# 堆叠操作会沿着指定的维度将张量一个接一个地放置在一起，不会改变张量内部的数据分布。\n",
    "# tensors\n",
    "# dim：拼接的维度\n",
    "# 使用 torch.stack() 将 a 和 b 沿着第一个维度堆叠\n",
    "c = torch.stack([a, b], dim=0)\n",
    "print(\"torch.stack():\")\n",
    "print(c)\n",
    "print(c.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T07:12:31.268940Z",
     "start_time": "2023-09-20T07:12:31.262129Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]]), tensor([[[ 7,  8,  9],\n",
      "         [10, 20, 30]]]))\n"
     ]
    }
   ],
   "source": [
    "print(torch.chunk(c, 2, dim=0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T07:15:46.335564Z",
     "start_time": "2023-09-20T07:15:46.305911Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]), tensor([[ 7,  8,  9],\n",
      "        [10, 20, 30]]))\n"
     ]
    }
   ],
   "source": [
    "print(torch.chunk(d, 2, dim=0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T07:16:01.005440Z",
     "start_time": "2023-09-20T07:16:00.983056Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1, 2, 3]]), tensor([[4, 5, 6]]), tensor([[7, 8, 9]]), tensor([[10, 20, 30]]))\n"
     ]
    }
   ],
   "source": [
    "# split 分割\n",
    "print(torch.split(d, 1, dim=0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T07:17:25.716755Z",
     "start_time": "2023-09-20T07:17:25.709298Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 张量的计算\n",
    "## 加减乘除\n",
    "\n",
    "## 复合计算 （简洁化）\n",
    "\n",
    "\n",
    "\n",
    "## 线性回归\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
